# Метрики и оптимизация

## Задача регрессии

### Средний модуль отклонения

Самое банальное что можем сделать.

$MAE = \frac{1}{m} \sum_{i=1}^m |a_i - y_i|$

Если подбираем константную модель, то $a$ это медиану

### Средний квадрат отклонения

$MSE = \frac{1}{m} \sum_{i=1}^m |a_i - y_i|^2$

Если подбираем константную модель, то $a$ это среднее

### Root MSE

$RMSE = \sqrt{\frac{1}{m} \sum_{i=1}^m |a_i - y_i|^2}$

### Функция Хьюбера и logcosh

logcosh -- редкий зверь.

Хбюбер -- будем встречать периодически. Это смесь модуля и параболы. Чтобы мна маленьких была парабола, на больших
квадрат. Но функция непрерына и гладкая

### Различия MSE и MAE

Усточйсивость к выбросам.

MSE зачастую более устойчив к выбросам

### Обобщения

Корень какой-то степени из суммы разностей функцией в какой-то степени.

Функциям зачастую алгоритм (в финансовых задачах)

### Symmetric mean absolute percentage error

SMAPE

Берём цену акций.

- Говорим 1, она 2.
- Говорим 100, она 102

Ошибка вроде одинаковое, но если добавляем проценты, то сильно много чего меняется

- SMAPE
- MAPE - среднее отклонение
- PMAD - другой принцип нормировки. Такая функция ошибки не придаёт какого-то особо смысла.

### Несимметричные функции потерь

По разному ошибка, в зависимости от того предсказали мы больше значения или меньше.

Итоги в регрессии

- MAE
- MSE
- Процентные функции
- Несимметричные ошибки
- Ошибки с точностью до порога

## Задача бинарной классификации

### Confusion Matrix в задаче классификации с двумя классами

Строим таблицу из суммы правильных\неправильных для каждого класса

True Negative, False Positive, False Negative, True Positive

Ошибка 1-го рода $FP / m $

Ошибка 2-го рода $FN / m $

### Точность (Accuracy)

$Accuracy = \frac{TN + TP}{TN + FN + TP + FP}$

### Полнота (Recall)

$TPR = R = \frac{TP}{TP + FN}

Какой процент объектов положительного класса мы правильно классифициировали

### Точность (Precision)

$PPV = P = \frac{TP}{TP + FP}$

Какой процент положительных объектов (т.е. тех, что мы считаем положительными) правильно классифицирован

### Специфичность (Specifity, True Negative Rate)

$TNR = R_0 = \frac{TN}{TN + FP}$

Процент правильно классифицированных объектов негативного класса. Полнота для негативного класса!

### False Positive Rate

$FPR = \frac{FP}{TN + FP} = 1 - TNR = 1 - Specificity$

Доля объектов негативного класса, которых мы ошибочно отнесли к положительному

### F-score

$F_1$ score

$\frac{2}{\frac{1}{P} + \frac{1}{R}} = \frac{2TP}{2TP + FP + FN}$

$F_{\beta}$ score
$\frac{2}{\frac{\alpha}{P} + \frac{1 - \alpha}{R}} = (1+\beta^2)\frac{PR}{R + \beta^2 P}$

### Почему используется F-мера

Можно сколь угодно улучшать один из показателей, если второй не увеличивается, то качество ограничено

## Задача нечёткой бинарной классификации

Теперь выдаём оценку принадлежности к классу 1

### Log Loss

В задаче классификации с двумя непересекающимися классами (0, 1), когда ответ - вероятность принадлежности к классу 1

Эта функция хороша тем, что когда мы на неё настраиваемся, алгоритм учится предсказывать вероятность принадлежности к
классу 


#### Методы калиборвки
Калибровка Платта (Platt calibration) - для SVM

$a(x) = sigmoid(\alpha r(x) + \beta)$


### ROC и AUC ROC
ROC = receiver operating characteristic

Функционал зависит не от конкретных значений, а от их порядка

AUC = area under the curve


Смысл AUC -- число правильно отсортированных пар. 

ЭТО СЛОЖНО ОБЪЯСНИТЬ ЗАКАЗЧИКУ

Плохо то, что любое прибавление\умножение константы не изменит площадь 

### GINI в машинном обучении
Кривая Лоренца

PR = Positive rate

gini = 2 AUCROC - 1


Коэффициент Джини - отношение площадей (Кривая лоренца / (Кривая лоренца + идеальный алгоритм))

### Gini в задаче регрессии


## Полуитоги
### AUC ROC
Плюсы: 
- В задачах, где важен порядок
- Учитывает разную мощность классов 
- Не важны значения, важен порядок
- Можно использовать для оценки признаков 

- Завышает качество
- Оценивает не конкретный классификатор, а регрессию
- Сложно объяснить заказчику
- Не путать классификацию и регрессию